{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <font color='red'> Tutorial start: 2:50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tells the notebook not to display warnings:\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Libraries that this notebook will use:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "# Helps the maps display nicely in the notebook:\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [30, 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with and visualizing large datasets\n",
    "- Dealing with missing values\n",
    "- Filtering and selecting for certain rows and columns with ```.iloc[]``` and ```.loc[]```\n",
    "- Grouping data by specific attributes with ```.groupby()```\n",
    "- Working with temporal and categorial data and plotting lineplots and barplots\n",
    "- Reviewing list comprehensions\n",
    "- Merging two dataframes with ```.merge()```\n",
    "- Plotting choropleth maps with GeoPandas\n",
    "\n",
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today we're going to extend our Pandas and Geopandas knowledge to manipulate and visualize an existing large dataset. This dataset is a random sample of tweets collected over time (2012 to 2015) in Alameda County. The most relevant columns are the tweet ID, user ID, latitude, longitude, date, and census tract number.\n",
    "\n",
    "First, we need to clean the data. This data is relatively clean, but some columns have missing values, which may be problematic when you're trying to visualize, analyze, or model the data. There are many ways to deal with missing values, but today we're going to go over one: simply getting rid of them.\n",
    "\n",
    "Now, let's read in the data (from a .csv file) into Pandas. We'll call the variable for the dataframe ```tweets```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "      <th>id</th>\n",
       "      <th>u_id</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>date</th>\n",
       "      <th>tract</th>\n",
       "      <th>home_tract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100394</td>\n",
       "      <td>1706781</td>\n",
       "      <td>11348429</td>\n",
       "      <td>7.460734e-286</td>\n",
       "      <td>1.112537e-308</td>\n",
       "      <td>37.533737</td>\n",
       "      <td>-122.047722</td>\n",
       "      <td>2013-06-02T18:30:45Z</td>\n",
       "      <td>6.001444e+09</td>\n",
       "      <td>6.001442e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>636317</td>\n",
       "      <td>3308963</td>\n",
       "      <td>22737593</td>\n",
       "      <td>2.385919e-280</td>\n",
       "      <td>1.112537e-308</td>\n",
       "      <td>37.721548</td>\n",
       "      <td>-122.160706</td>\n",
       "      <td>2014-01-16T06:59:00Z</td>\n",
       "      <td>6.001433e+09</td>\n",
       "      <td>6.001443e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>656240</td>\n",
       "      <td>438554</td>\n",
       "      <td>2772585</td>\n",
       "      <td>4.137202e-291</td>\n",
       "      <td>1.112537e-308</td>\n",
       "      <td>37.775331</td>\n",
       "      <td>-122.181411</td>\n",
       "      <td>2012-10-28T11:26:25Z</td>\n",
       "      <td>6.001408e+09</td>\n",
       "      <td>6.061023e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>319121</td>\n",
       "      <td>2707739</td>\n",
       "      <td>18474419</td>\n",
       "      <td>6.367822e-282</td>\n",
       "      <td>1.112537e-308</td>\n",
       "      <td>37.674357</td>\n",
       "      <td>-122.121426</td>\n",
       "      <td>2013-11-12T06:05:19Z</td>\n",
       "      <td>6.001436e+09</td>\n",
       "      <td>6.001436e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>541520</td>\n",
       "      <td>2157806</td>\n",
       "      <td>14595412</td>\n",
       "      <td>2.263115e-284</td>\n",
       "      <td>1.112537e-308</td>\n",
       "      <td>37.633599</td>\n",
       "      <td>-122.095015</td>\n",
       "      <td>2013-08-02T18:15:04Z</td>\n",
       "      <td>6.001437e+09</td>\n",
       "      <td>6.001437e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1             id           u_id  \\\n",
       "0      100394       1706781        11348429  7.460734e-286  1.112537e-308   \n",
       "1      636317       3308963        22737593  2.385919e-280  1.112537e-308   \n",
       "2      656240        438554         2772585  4.137202e-291  1.112537e-308   \n",
       "3      319121       2707739        18474419  6.367822e-282  1.112537e-308   \n",
       "4      541520       2157806        14595412  2.263115e-284  1.112537e-308   \n",
       "\n",
       "         lat         lon                  date         tract    home_tract  \n",
       "0  37.533737 -122.047722  2013-06-02T18:30:45Z  6.001444e+09  6.001442e+09  \n",
       "1  37.721548 -122.160706  2014-01-16T06:59:00Z  6.001433e+09  6.001443e+09  \n",
       "2  37.775331 -122.181411  2012-10-28T11:26:25Z  6.001408e+09  6.061023e+09  \n",
       "3  37.674357 -122.121426  2013-11-12T06:05:19Z  6.001436e+09  6.001436e+09  \n",
       "4  37.633599 -122.095015  2013-08-02T18:15:04Z  6.001437e+09  6.001437e+09  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.read_csv(\"tweets.csv\")\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look of how many rows we have before deleting the rows with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "185793"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets) ##185793"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also look at what the column names of the dataset are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Unnamed: 0.1', 'Unnamed: 0.1.1', 'id', 'u_id', 'lat',\n",
       "       'lon', 'date', 'tract', 'home_tract'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we clean, let's view the rows with missing values first. The code below is how we can do so. Let's break it down.\n",
    "\n",
    "```tweets.isnull().any(axis=1)``` is a conditional statement that is a True or False value denoting if the corresponding row has a missing value.\n",
    "```tweets[tweets.isnull().any(axis=1)]``` selects the rows for where the above conditional is True.\n",
    "\n",
    "Note: axis = 0 would select the columns.\n",
    "\n",
    "Run the code below to display the first five rows that have missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "      <th>id</th>\n",
       "      <th>u_id</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>date</th>\n",
       "      <th>tract</th>\n",
       "      <th>home_tract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2123</th>\n",
       "      <td>399539</td>\n",
       "      <td>5274304</td>\n",
       "      <td>36104757</td>\n",
       "      <td>2.476797e-275</td>\n",
       "      <td>1.112537e-308</td>\n",
       "      <td>37.793657</td>\n",
       "      <td>-122.274530</td>\n",
       "      <td>2014-08-10T23:45:53Z</td>\n",
       "      <td>6.001983e+09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27735</th>\n",
       "      <td>635943</td>\n",
       "      <td>375055</td>\n",
       "      <td>2373720</td>\n",
       "      <td>3.019609e-291</td>\n",
       "      <td>1.112537e-308</td>\n",
       "      <td>37.606953</td>\n",
       "      <td>-122.141182</td>\n",
       "      <td>2012-10-23T10:05:27Z</td>\n",
       "      <td>6.001437e+09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29878</th>\n",
       "      <td>211628</td>\n",
       "      <td>1445013</td>\n",
       "      <td>9502506</td>\n",
       "      <td>3.581308e-286</td>\n",
       "      <td>1.112537e-308</td>\n",
       "      <td>37.822021</td>\n",
       "      <td>-122.311737</td>\n",
       "      <td>2013-05-20T11:05:43Z</td>\n",
       "      <td>6.001402e+09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58387</th>\n",
       "      <td>64843</td>\n",
       "      <td>4540043</td>\n",
       "      <td>30960839</td>\n",
       "      <td>1.471807e-277</td>\n",
       "      <td>1.112537e-308</td>\n",
       "      <td>37.651870</td>\n",
       "      <td>-122.090782</td>\n",
       "      <td>2014-05-10T21:29:06Z</td>\n",
       "      <td>6.001437e+09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60532</th>\n",
       "      <td>537336</td>\n",
       "      <td>6585241</td>\n",
       "      <td>44873012</td>\n",
       "      <td>6.163226e-271</td>\n",
       "      <td>1.112537e-308</td>\n",
       "      <td>37.867670</td>\n",
       "      <td>-122.312500</td>\n",
       "      <td>2015-02-08T06:36:41Z</td>\n",
       "      <td>6.001422e+09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1             id           u_id  \\\n",
       "2123       399539       5274304        36104757  2.476797e-275  1.112537e-308   \n",
       "27735      635943        375055         2373720  3.019609e-291  1.112537e-308   \n",
       "29878      211628       1445013         9502506  3.581308e-286  1.112537e-308   \n",
       "58387       64843       4540043        30960839  1.471807e-277  1.112537e-308   \n",
       "60532      537336       6585241        44873012  6.163226e-271  1.112537e-308   \n",
       "\n",
       "             lat         lon                  date         tract  home_tract  \n",
       "2123   37.793657 -122.274530  2014-08-10T23:45:53Z  6.001983e+09         NaN  \n",
       "27735  37.606953 -122.141182  2012-10-23T10:05:27Z  6.001437e+09         NaN  \n",
       "29878  37.822021 -122.311737  2013-05-20T11:05:43Z  6.001402e+09         NaN  \n",
       "58387  37.651870 -122.090782  2014-05-10T21:29:06Z  6.001437e+09         NaN  \n",
       "60532  37.867670 -122.312500  2015-02-08T06:36:41Z  6.001422e+09         NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this\n",
    "# Display rows with missing values in any column.\n",
    "tweets[tweets.isnull().any(axis=1)].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There should be a total of 26 rows with missing values in the dataset. Run the next cell with the len() function to confirm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets[tweets.isnull().any(axis=1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's actually delete the rows, using the function \n",
    "\n",
    "```dataframename.dropna(axis=0, how='any')```\n",
    "\n",
    "which drops any row where there is a missing value in any column. Use ```dropna(...)``` on the dataframe ```tweets```. Use ```len()``` to count how many rows are remaining. You should see that the row count has dropped by 81."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##fill in the ...\n",
    "tweets = ...\n",
    "len(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to display the rows with missing values. There should be none."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[tweets.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to reset the indices and get rid of extraneous columns. We will explain how this works in a later section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets.reset_index()\n",
    "tweets = tweets.loc[:, ['id', 'u_id', 'lat', 'lon', 'date', 'tract', 'home_tract']]\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the number of tweets over time <font color='red'> (22:40)\n",
    "### Converting to DateTime\n",
    "Notice that we have temporal data in the ```tweets``` dataset. We can use the temporal information to plot the number of tweets over time. However, right now the temporal information is so fine grain, right down towards the second, that we probably won't be able to see any patterns. So for this exercise, *we only want the date information*. \n",
    "\n",
    "Now let's take a step backwards first.\n",
    "In our dataframe, the temporal information is stored as **strings**, but for Python to understand these strings as temporal information, we'll need to convert them to **Python DateTime** objects. From then we can get the dates only.\n",
    "\n",
    "When we run the following code, we can see that the individual dates are currently stored as strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this\n",
    "print(tweets['date'][0])\n",
    "print(type(tweets['date'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert them into DateTime objects, we simply need to use the \n",
    "\n",
    "```pd.to_datetime(<the list, array, or series you want to convert>)```\n",
    "\n",
    "function, which outputs the converted values. In the following cell, set the date column equal to the converted values you get with ```pd._to_datetime(...)```. When you run ```print()``` lines, you should see that the type of the dates has now changed into \"Timestamp\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##fill in ...\n",
    "tweets['date'] = ...\n",
    "print(tweets['date'][0])\n",
    "print(type(tweets['date'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to get the date from a Timestamp, which is the first part of the output above. To do this, we will use a list comprehension.\n",
    "\n",
    "To remind you, here's the structure of a list comprehension. Let's say you have a list called ```nums``` with values ```[1, 2, 3]``` and want to add 1 to each of the values. The variable n will take on every value in the list called nums, and then we add 1 to every value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = [1, 2, 3]\n",
    "[n + 1 for n in nums]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##If we wanted to do the above with a for loop, it would look like this:\n",
    "\n",
    "nums = [1,2,3]\n",
    "new_nums = []\n",
    "for n in nums:\n",
    "    add_1 = n + 1\n",
    "    new_nums.append(add_1)\n",
    "    \n",
    "new_nums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A list comprehension runs faster than a for loop because we do everything in a single line, whereas in a for loop, we have to go through more than one line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do the exercise below.\n",
    "\n",
    "To only get the date from a Timestamp, you just need to use the function \n",
    "\n",
    "```<the timestamp>.date()```. \n",
    "\n",
    "To convert all the values in our column, we can use a list comprehension. Set the date column equal to the output of your list comprehension.\n",
    "\n",
    "When you run the ```print()``` lines, you can see that type of the dates has now changed to \"datetime.date\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##fill in ...\n",
    "tweets['date'] = ...\n",
    "print(tweets['date'][0])\n",
    "print(type(tweets['date'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping tweets by date\n",
    "Now we want to aggregate by date. Specifically, we want to get the count of tweets per date. We can use the function \n",
    "\n",
    "```<the dataframe>.groupby(<column name to group by>).<an aggregating function, e.g. count(), max(), mean()>```, \n",
    "\n",
    "which outputs a grouped dataframe, to do so. Which aggregating function should we use? Set a variable called ```tweets_by_date``` equal to the grouped dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##fill in ...\n",
    "tweets_by_date = ...\n",
    "tweets_by_date.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we are going to perform some dataframe operations that will prepare our data for visualization. Pay attention, as you will need to do something similar later on.\n",
    "\n",
    "Notice how the date column is now bolded. Pandas now views the date column as an index, which is like an address. However, we want it to be a normal column again if we want to access it with attributes like ```loc``` and ```iloc```. We use ```reset_index()``` to reset the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this\n",
    "tweets_by_date = tweets_by_date.reset_index()\n",
    "tweets_by_date.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a lot of columns that we don't need. Remember ```.iloc[]```? We'll use ```.iloc[]``` to select only the first two columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this\n",
    "tweets_by_date = tweets_by_date.iloc[:, 0:2]\n",
    "tweets_by_date.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second column has a weird name. ```tweets_by_date.columns``` gets the column names of the dataframe. We can set them equal to a list with the new column names to rename them. Let's run the cell below to rename the id column to number of tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this\n",
    "tweets_by_date.columns = ['date', 'number of tweets']\n",
    "tweets_by_date.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Matplotlib to plot a line plot: Number of tweets vs. date\n",
    "Time to plot! Use \n",
    "\n",
    "```plt.plot(<list, array, or series of the x values>, <the y values>)```\n",
    "\n",
    "to plot the number of tweets vs. time. We've labeled the axes and title. Study the code, as you will need to do it yourself later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##fill in the ... with your plotting code\n",
    "plt.figure(figsize=[18, 7])\n",
    "...\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('number of tweets')\n",
    "plt.title('Number of Tweets over Time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of tweets by tract - Barplots <font color='red'> (44:20)\n",
    "### Grouping tweets by census tract\n",
    "Remember how we grouped tweets by date? Do the same, but this time, group instead by ```tract``` and aggregate with count(). Set the output equal to a variable called ```tweets_by_tract```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##fill in the ...\n",
    "tweets_by_tract = ...\n",
    "tweets_by_tract.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas now sees the tract as an index, but we don't want that. Set the indices back to normal using ```reset_index()```, referencing the previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##fill in the ...\n",
    "tweets_by_tract = ...\n",
    "tweets_by_tract.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only want the tract number and counts. Use ```.iloc[]``` to select only the first two columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##fill in the ...\n",
    "tweets_by_tract = ...\n",
    "tweets_by_tract.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now we want to rename this ```id``` column to ```number of tweets```. Can you recall from the previous section how to do that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##fill in the ...\n",
    "tweets_by_tract.columns = ...\n",
    "tweets_by_tract.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting tweet counts in descending order\n",
    "There are 360 tracts, which is too much to plot on one bar plot. Let's graph the top 10 tracts with the most tweets. \n",
    "\n",
    "First, let's set ```tweets_by_tract``` to a sorted version of itself. Use the function:\n",
    "\n",
    "```<the dataframe>.sort_values(by=<column name>, ascending=False)```\n",
    "\n",
    "which outputs a sorted dataframe, to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##fill in the ...\n",
    "tweets_by_tract = ...\n",
    "tweets_by_tract.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: ascending = False makes it so that we sort the number of tweets in descending order. ascending = True will sort them in ascending order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert census tract numbers to strings\n",
    "Currently, the census tracts are stored as integers. If you tried to plot with these, the barplot would not display correctly. Additionally, census tracts are not numerical data, but categorical data. So, instead we want to store each census tract as a **string**. We can use a list comprehension to do so!\n",
    "\n",
    "Create a new column in ```tweets_by_tract``` named ```GEOID``` with these census tract strings.\n",
    "\n",
    "*Important Hint:*\n",
    "Make sure that the strings are of a specific format.\n",
    "The tract numbers are currently of the **float** type, which means they have decimal points (e.g. 10.0). We want them to be **integers** (e.g. 10) before we convert them into strings.\n",
    "\n",
    "You can use ```int()``` to convert a float first to an integer. Then use ```str()``` to convert the integer into a string! To do both at once, use ```str(int(...))```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##fill in the ...\n",
    "tweets_by_tract['GEOID'] = ...\n",
    "tweets_by_tract.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to plot the top 10 tracts with the highest counts. Use ```.iloc[]```to select the top 10 GEOID's and the top 10 tweet counts. Remember: columns have indices starting at 0! Which index are the GEOID and number of tweets columns in? After this, use\n",
    "\n",
    "```plt.bar(<the list, array, or series of x values>, <the y values>)```\n",
    "\n",
    "to plot a bar plot (note: if we want a horizontal bar plot, simply add an 'h' after bar. But for this, we will get vertical bars instead). Make sure to add a labels to the x and y axes, as well as the title. Refer to the previous section for how to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##fill in the ...\n",
    "top_10_tracts = ...\n",
    "top_10_tweetcounts = ...\n",
    "plt.figure(figsize=[18, 10])\n",
    "...\n",
    "...\n",
    "...\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving on to GeoPandas: Visualizing number of tweets per census tract spatially  <font color ='red'> (59:20)\n",
    "The bar plot is fascinating, but we're not any more enlightened than before, because most people don't memorize census tract numbers. A better way would be to analyze the data spatially, which means using GeoPandas!\n",
    "\n",
    "Read in the alameda data from the previous lab. This contains the Shapely geometry polygons that we'll need to map our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "alameda = gpd.read_file('alameda_shapefiles')\n",
    "alameda.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's recall what the column names are for this dataset. Run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alameda.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't need all of these columns. Use ```.loc[]``` to select only the columns named:\n",
    "GEOID, female, male, medianage, total_pop, and geometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alameda = alameda.loc[:, ['GEOID', 'female', 'male', 'medianage', 'total_pop', 'geometry']]\n",
    "alameda.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging dataframes\n",
    "Notice how the ```alameda``` dataset contains a variety of values by GEOID. Conveniently, so does our ```tweets_by_tract``` dataset! If we simply add the tweet counts to the alameda dataset, we would be able to plot a chloropleth map on the number of tweets per census tract.\n",
    "\n",
    "To do so, we're going to perform an operation called a **merge** or **join**. We're going to perform the join on the ```GEOID``` column, so that the tweet count data corresponds correctly to the right census tract.\n",
    "\n",
    "First, we need to fix a slight problem. The ```alameda GEOID``` column values have a 0 before, while the ```tweets_by_tract GEOID``` column values don't. This is easy, we can just concatenate a '0' in front of each census tract number in ```tweets_by_tract``` using a list comprehension.\n",
    "\n",
    "Below is a quick review on how string concatenation works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"pineapple\" + \"pen\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, fill in the cell below with a list comprehension that append a '0' in f ront of each GEOID.\n",
    "\n",
    "Hint: recall the str(int()) trick from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##fill in the ...\n",
    "tweets_by_tract['GEOID'] = ...\n",
    "tweets_by_tract.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to merge! Use the function\n",
    "\n",
    "```<a dataframe>.merge(<another dataframe>, on=<column name to merge on>)```\n",
    "\n",
    "and set the output equal to variable called ```combined```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##fill in\n",
    "combined = ...\n",
    "combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are other types of merging techniques in python. By default, if we do not specify what type of merge we do, python will treat is as a ```left``` join, which means if will keep all the unique values for the table on the left of the .merge method. To learn more about other types of joins, see the link below:\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.join.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the chloropleths we created in the last lab. Now create a chloropleth map of the number of tweets per census tract.\n",
    "\n",
    "Reference:\n",
    "```<the geodataframe>.plot(column=<column name>, legend=True, figsize=[18, 10])```\n",
    "\n",
    "Remember to add a title and remove the axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill in the ... with your code and replace the next line with combined.plot(...)\n",
    "\n",
    "##replace this line with combined.plot(...)\n",
    "bounds = ...\n",
    "#minx = bounds[0]\n",
    "#miny = bounds[1]\n",
    "#maxx = bounds[2]\n",
    "#maxy = bounds[3]\n",
    "text_properties = {'ha': 'center', 'va': 'center', 'fontsize' : 20} \n",
    "#plt.text(maxx + (maxx-minx)/4.5, (maxy - miny)/2 + miny, 'Percentage of Tweet Counts by Census Tract', text_properties, rotation=90)\n",
    "plt.title(..., fontsize = 30)\n",
    "plt.axis(..);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks so much better than the bar plot! But what if some census tracts only have a lot of tweets because they have a larger population size? Instead, we should plot number of tweets per capita.\n",
    "\n",
    "Make a new column in ```combined``` called ```avg tweets per capita```. Set it equal to ```number of tweets``` divided by ```total_pop```. Then plot the new chloropleth map. Remember to add the title and remove the axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##fill in the ... with your code\n",
    "combined[\"avg tweets per capita\"] = ...\n",
    "\n",
    "##Let's see what the table looks now with the new column:\n",
    "combined.head() ##scroll to the right if needed to see all the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##fill in the ... with your code to plot\n",
    "combined.plot(...)\n",
    "plt.text(maxx + (maxx-minx)/4.5, (maxy - miny)/2 + miny, 'Percentage of Tweet Counts by Census Tract', text_properties, rotation=90)\n",
    "plt.title(...)\n",
    "plt.axis(...);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are by no means the only visualizations you can create with the ```combined``` dataset. In the cell below, create your own visualization! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your own visualization here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "If you're interested in exploring more about data science, Berkeley's [Data 8](https://www.inferentialthinking.com/chapters/intro.html) and [Data 100](https://www.textbook.ds100.org/) textbooks are very well-written with interactive links to follow along.\n",
    "\n",
    "There are also websites like [DataCamp](https://www.datacamp.com/courses) and [DataQuest](https://www.dataquest.io/course/python-for-data-science-fundamentals/) that offer online interactive courses in R, Python, and SQL, many of them for free.\n",
    "\n",
    "If you're stuck trying to work on a project, [Data Peer Consulting](https://data.berkeley.edu/education/data-peer-consulting) at the Division of Data Sciences could be helpful to you.\n",
    "\n",
    "If you're looking for more specialized help, the [D-lab](https://dlab.berkeley.edu/) which focuses on data science applications to the social sciences specifically, holds [workshops](https://dlab.berkeley.edu/training) and [consulting](https://dlab.berkeley.edu/consulting), many on geospatial data.\n",
    "\n",
    "---\n",
    "### Author: Rebekah Tang\n",
    "\n",
    "### References:\n",
    "- GeoPandas Mapping Documentation: http://geopandas.org/mapping.html\n",
    "- Pandas Documentation: https://pandas.pydata.org/pandas-docs/stable/reference/frame.html\n",
    "- Matplotlib Documentation: https://matplotlib.org/api/pyplot_summary.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
